# ğŸ›’ Week 2 â€“ Task 3: Customer Segmentation using K-Means

## ğŸ“˜ Project Overview
In this task, I implemented **Customer Segmentation** using the popular **Mall Customers dataset**.  
The goal is to group customers based on their **Age**, **Annual Income**, and **Spending Score** using **K-Means Clustering**.

This task is part of the Edulumos Machine Learning Internship (Week 2, Task 3 â€“ Customer Universe: Grouping Shoppers with K-Means).

---

## ğŸ§  Objective
To segment customers into meaningful groups based on their shopping behavior so that businesses can:
- Identify **high-value customers**
- Understand **spending patterns**
- Design better **targeted marketing strategies**

---

## ğŸ“‚ Dataset Description
The dataset contains **200 customers** with the following columns:

| Column | Description |
|--------|-------------|
| `CustomerID` | Unique ID assigned to each customer |
| `Gender` | Male / Female |
| `Age` | Age of the customer |
| `Annual Income (k$)` | Annual income in thousand dollars |
| `Spending Score (1-100)` | Score assigned based on spending habits and behavior |

---

## ğŸ”§ Steps Performed

### 1ï¸âƒ£ Import Libraries & Load Data
Loaded the CSV file using **pandas** and checked for:
- Data shape
- Data types
- Missing values

### 2ï¸âƒ£ Data Preprocessing
- Dropped `CustomerID` (not useful for clustering)
- Encoded `Gender` column:  
  - Male â†’ 0  
  - Female â†’ 1  

### 3ï¸âƒ£ Feature Selection
Used the key features for clustering:
- `Age`
- `Annual Income (k$)`
- `Spending Score (1-100)`
- (Optionally `Gender` after encoding)

### 4ï¸âƒ£ Feature Scaling
Applied **StandardScaler** to normalize features so that all variables contribute equally to distance calculation.

```python
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
```

### 5ï¸âƒ£ Choosing Number of Clusters â€“ Elbow Method
Used the **Elbow Method** by plotting **WCSS (Within-Cluster Sum of Squares)** vs **k** (number of clusters).

```python
from sklearn.cluster import KMeans

wcss = []
for k in range(2, 11):
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
    kmeans.fit(X_scaled)
    wcss.append(kmeans.inertia_)
```

The elbow curve suggested an optimal value of **k â‰ˆ 5** clusters.

### 6ï¸âƒ£ Applying K-Means
```python
kmeans = KMeans(n_clusters=5, random_state=42, n_init=10)
clusters = kmeans.fit_predict(X_scaled)
```

Added the cluster labels back to the original dataset as a new column `Cluster`.

### 7ï¸âƒ£ Visualization
Plotted clusters using:
- **Annual Income vs Spending Score**
- Different colors to represent clusters

This helps visualize:
- High-income, high-spending customers
- Low-income, low-spending customers
- Moderate groups

---

## ğŸ“Š Insights & Interpretation (Example)
Based on the clusters, we can interpret groups like:

- **Cluster 0** â†’ Low income, low spending â†’ Budget-conscious customers  
- **Cluster 1** â†’ High income, high spending â†’ Premium/VIP customers  
- **Cluster 2** â†’ High income, low spending â†’ Potential customers (untapped)  
- **Cluster 3** â†’ Young with high spending â†’ Trend-focused, brand-conscious  
- **Cluster 4** â†’ Moderate income & spending â†’ Average regular customers  

These insights help in **targeted marketing** and **customer relationship strategies**.

---

## ğŸ§ª Technologies Used
- Python  
- pandas, numpy  
- matplotlib, seaborn  
- scikit-learn (StandardScaler, KMeans)  

---

## ğŸ Conclusion
This task demonstrates how **unsupervised learning** can be used to understand customer behavior without labeled outputs.  
K-Means clustering allowed us to group shoppers into meaningful segments which are very useful in real-world business and marketing applications.

---

## ğŸ‘¨â€ğŸ’» Author
**Zafar Hussain**  
Edulumos Machine Learning Internship â€“ Week 2, Task 3
